{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2  Variability of Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import scipy.stats as scp\n",
    "from numpy import linalg as la\n",
    "from numpy import random as rand\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(X, y, L, n_folds=10):\n",
    "    '''\n",
    "    Synopsis:\n",
    "        w_opt, b_opt, lambda_opt = cross_validation(X, Y, L, n_folds=10)\n",
    "    Arguments:\n",
    "        X:            2D array of data (features x samples)\n",
    "        Y:            Vector of true labels (1 x samples)\n",
    "        L:            List of lambdas to cross validate (1 x #lambdas)\n",
    "        n_folds:      Number of nested folds\n",
    "    Output:\n",
    "        w_opt:        optimal weight vector\n",
    "        b_opt:        optimal bias\n",
    "        lambda_opt:   the lambda with the lowest MSE\n",
    "    '''\n",
    "    d, n = X.shape\n",
    "    samples_per_fold = int(n / n_folds)\n",
    "    \n",
    "    # set up a container for the resulting mse values (n_folds x #lambdas)\n",
    "    MSE = np.empty((n_folds, L.shape[0]))\n",
    "    mse_min = float('inf')\n",
    "    lambda_opt = _\n",
    "\n",
    "    for i, l in enumerate(L):\n",
    "        # loop over all possible lambdas\n",
    "        # using different permutation of samples\n",
    "        idx = np.arange(n) # np.random.permutation(n) # np.arange(n)\n",
    "        for j in range(n_folds):\n",
    "            # extract one fold for testing\n",
    "            idx_te = idx[j*samples_per_fold:(j+1)*samples_per_fold]\n",
    "            # get the train data\n",
    "            X_tr = np.delete(X, idx_te, axis=1)\n",
    "            y_tr = np.delete(y, idx_te, axis=1)\n",
    "            # get the test data\n",
    "            X_te = X[:,idx_te]\n",
    "            y_te = y[:,idx_te]\n",
    "            \n",
    "            # train the model\n",
    "            w, b = train(X_tr, y_tr, l)\n",
    "            # predict the labels\n",
    "            y_pred = predict(X_te, w, b)\n",
    "            # and compute the mse for this lambda and fold\n",
    "            MSE[j,i] = m_sq_error(y_te, y_pred)\n",
    "\n",
    "        # find the lambda with the lowest MSE\n",
    "        mse_this = MSE[:,i].mean()\n",
    "        if(mse_this < mse_min):\n",
    "            mse_min = mse_this\n",
    "            lambda_opt = l\n",
    "\n",
    "    return lambda_opt\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def m_sq_error(y, y_pred):\n",
    "    '''\n",
    "    Synopsis:\n",
    "        mse = m_sq_error(y, y_pred)\n",
    "    Arguments:\n",
    "        y:        Vector of true labels\n",
    "        y_pred:   Vector of predicted labels\n",
    "    Output:\n",
    "        mse:      The mean squared error\n",
    "    '''\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "def train(X, y, lmbda):\n",
    "    '''\n",
    "    Synopsis:\n",
    "        w, b = train(X, y, lmda)\n",
    "    Arguments:\n",
    "        X:     2D array of data (features x samples)\n",
    "        y:     Vector of true labels\n",
    "        lmda:  The regularisation value\n",
    "    Output:\n",
    "        w:     The computed weight vector (features x 1)\n",
    "        b:     The bias (scalar)\n",
    "    '''    \n",
    "    # covariance (d x d)\n",
    "    C = X.dot(X.T)\n",
    "    # reg, inv cov (d x d)\n",
    "    B = la.inv(C + np.identity(C.shape[0]) * lmbda)\n",
    "    # compute the weights (d x 1)\n",
    "    w = B.dot(X).dot(y.T)\n",
    "    # compute the bias b (scalar)\n",
    "    mu_c1 = X[:,y[0,:]==-1].mean(axis=1, keepdims=True)\n",
    "    mu_c2 = X[:,y[0,:]==1].mean(axis=1, keepdims=True)\n",
    "    b = w.T.dot(0.5*(mu_c1 + mu_c2))[0,0]\n",
    "    return w, b\n",
    "\n",
    "def predict (X,w,b):\n",
    "    return np.sign(w * X +b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 200\n",
    "\n",
    "def generate_data(n):\n",
    "    mu_1 = [0,1]\n",
    "    mu_2 = [1,0]\n",
    "    var1 =[2,0]\n",
    "    var2 =[0,2]\n",
    "\n",
    "    X_c1 = np.append(rand.multivariate_normal(mu_1, [var1,var2], n/2), rand.multivariate_normal(mu_1, [var1,var2], n/2), axis=0)\n",
    "    X_c2 = np.append(rand.multivariate_normal(mu_2, [var1,var2], n/2), rand.multivariate_normal(mu_2, [var1,var2], n/2), axis=0)\n",
    "    # create a data matrix of shape 120x3 where colums 0 and 1 are the dimensions and colum 2 being the label\n",
    "    X = np.vstack((X_c1, X_c2)).T\n",
    "    \n",
    "    y = np.vstack((np.ones((n,1)), np.ones((n,1))-2)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1 = plt.scatter(X_c1[:,0], X_c1[:,1], color='blue', label='class 0')\n",
    "p2 = plt.scatter(X_c2[:,0], X_c2[:,1], color='red', label='class 1')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 10**np.arange(-4, 4, 0.1)\n",
    "cross_validation(X,y,L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3 The Binomial Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_mass_binom (k,n,p):\n",
    "    a = comb(n,k)\n",
    "    b = (1-p)**(n-k)\n",
    "    return a*(p**k)*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = [1,3,15,28,50]\n",
    "N = [2,20,50,80,100]\n",
    "P = [0.1,0.2,0.3,0.4,0.5]\n",
    "\n",
    "results = np.zeros((5,5,5))\n",
    "ck= 0\n",
    "cn = 0\n",
    "cp = 0\n",
    "for k in K:\n",
    "    cn = 0\n",
    "    for n in N:\n",
    "        cp = 0\n",
    "        for  p in P:\n",
    "            results[ck][cn][cp] = prob_mass_binom(k,n,p)\n",
    "            cp = cp+1\n",
    "        cn = cn+1\n",
    "    ck = ck+1\n",
    "    \n",
    "#for i in range(0,ck):\n",
    "#    plt.figure()\n",
    "#    plt.contour(P,N,results[i,:,:])\n",
    "#    plt.title(K[i])\n",
    "\n",
    "#fig = plt.figure()\n",
    "#ax = plt.axes(projection='3d')\n",
    "\n",
    "for i in range(0,ck):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(P, N, results[i,:,:], cmap=plt.cm.jet, rstride=1, cstride=1, linewidth=0)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 b)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
